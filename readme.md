Capteurs de PRESSION (100 Hz) : PS
Capteur de PUISSANCE MOTEUR (100 Hz): EPS
Capteurs de DÃ‰BIT (10 Hz) : FS
Capteurs de TEMPÃ‰RATURE (1 Hz) : TS
Capteur de VIBRATION (1 Hz) : VS
ğŸŸ¡ Capteurs VIRTUELS (calculÃ©s) :CE.txt â†’ Cooling Efficiency , CP.txt â†’ Cooling Power , SE.txt â†’ Efficiency factor

a utiliser : ts_features_global_aggregation, PS_all_cycles_windowed_mean_min_max, 


# ğŸ“š RÃ‰SUMÃ‰ COMPLET : PIPELINE DE PRÃ‰PARATION DES DONNÃ‰ES

## ğŸ¯ Objectif Global

PrÃ©parer un **dataset complet** pour prÃ©dire la **condition de la valve hydraulique** Ã  partir de **13 capteurs multi-frÃ©quences** mesurant pression, dÃ©bit, tempÃ©rature et vibration.

---

## ğŸ“Š 1. DonnÃ©es Brutes Initiales

### Capteurs Disponibles (13 au total)

| Type | Capteurs | FrÃ©quence | Points/cycle | Fichiers |
|------|----------|-----------|--------------|----------|
| **Pression** | PS1, PS2, PS3, PS5, PS6 (PS4 exclu) | 100 Hz | 6000 | PS1.txt, PS2.txt, etc. |
| **Pression externe** | EPS1 | 100 Hz | 6000 | EPS1.txt |
| **DÃ©bit** | FS1, FS2 | 10 Hz | 600 | FS1.txt, FS2.txt |
| **TempÃ©rature** | TS1, TS2, TS3, TS4 | 1 Hz | 60 | TS1.txt, TS2.txt, etc. |
| **Vibration** | VS1 | 1 Hz | 60 | VS1.txt |

### Labels
- **Fichier** : profile.txt (colonne 1 = valve_condition)
- **Classes** : 100 (optimal), 90, 80, 73 (dÃ©faillant)
- **Cycles** : 2205 cycles complets de 60 secondes chacun

---

## ğŸ”§ 2. StratÃ©gies de RÃ©duction par FrÃ©quence

### âš¡ Capteurs Haute FrÃ©quence (100 Hz) : **FENÃŠTRAGE**

**Capteurs concernÃ©s : PS (5 capteurs) + EPS (1 capteur)**

- **ProblÃ¨me** : 6000 points/cycle = trop de donnÃ©es brutes
- **Solution** : FenÃªtrage de **100 points** (= 1 seconde)
- **RÃ©sultat** : 60 fenÃªtres/cycle
- **Statistiques par fenÃªtre** : mean, min, max, std (4 stats)
- **Formule** : 60 fenÃªtres Ã— 4 stats = **240 features/capteur**

**RÃ©duction :**
- PS : 6000 points â†’ 1200 features (5 capteurs Ã— 240)
- EPS : 6000 points â†’ 240 features (1 capteur Ã— 240)

**Fichiers crÃ©Ã©s :**
- `PS_all_cycles_windowed_mean_min_max.txt` (2205 Ã— 1200)
- `EPS_features_windowed_100pts.txt` (2205 Ã— 240)

---

### ğŸŒŠ Capteurs FrÃ©quence Moyenne (10 Hz) : **FENÃŠTRAGE**

**Capteurs concernÃ©s : FS (2 capteurs)**

- **ProblÃ¨me** : 600 points/cycle = moyennement volumineux
- **Solution** : FenÃªtrage de **10 points** (= 1 seconde)
- **RÃ©sultat** : 60 fenÃªtres/cycle
- **Statistiques par fenÃªtre** : mean, min, max, std (4 stats)
- **Formule** : 60 fenÃªtres Ã— 4 stats = **240 features/capteur**

**RÃ©duction :**
- FS : 600 points â†’ 480 features (2 capteurs Ã— 240)

**Fichier crÃ©Ã© :**
- `FS_features_windowed_10pts.txt` (2205 Ã— 480)

---

### ğŸŒ Capteurs Basse FrÃ©quence (1 Hz) : **AGRÃ‰GATION GLOBALE**

**Capteurs concernÃ©s : TS (4 capteurs) + VS (1 capteur)**

- **ProblÃ¨me** : 60 points/cycle = dÃ©jÃ  compact
- **Constat** : FenÃªtrer 1 point par fenÃªtre n'a aucun sens !
- **Solution** : **AgrÃ©gation globale par cycle**
- **Statistiques globales** : mean, min, max, std, **slope** (5 stats)
- **Formule** : 5 stats globales = **5 features/capteur**

**RÃ©duction :**
- TS : 60 points â†’ 20 features (4 capteurs Ã— 5)
- VS : 60 points â†’ 5 features (1 capteur Ã— 5)

**Fichiers crÃ©Ã©s :**
- `TS_features_global_aggregation.txt` (2205 Ã— 20)
- `VS_features_global_aggregation.txt` (2205 Ã— 5)

**Avantage de l'agrÃ©gation** :
- âœ… Beaucoup plus simple (5 vs 240 features)
- âœ… Capture l'essence : tendance + variabilitÃ© + amplitude
- âœ… Pas de surapprentissage avec trop de features
- âœ… Pente (slope) ajoute l'information de tendance temporelle

---

## ğŸ”— 3. ConcatÃ©nation : Dataset Master

### Principe Fondamental
**Tous les capteurs ont enregistrÃ© les MÃŠMES cycles en MÃŠME TEMPS !**

```
Cycle Physique 1 (60 secondes) :
â”œâ”€ PS ligne 0  : Mesures de pression
â”œâ”€ FS ligne 0  : Mesures de dÃ©bit
â”œâ”€ EPS ligne 0 : Mesure de pression externe
â”œâ”€ TS ligne 0  : Mesures de tempÃ©rature
â””â”€ VS ligne 0  : Mesure de vibration
```

### ProblÃ¨me RencontrÃ©
- PS avait **2206 cycles** au lieu de **2205**
- **Solution** : Tronquer PS aux 2205 premiers cycles

### ConcatÃ©nation Horizontale
```python
master_dataset = [PS | FS | EPS | TS | VS]
                 â†“    â†“    â†“    â†“    â†“
               1200 + 480 + 240 + 20 + 5 = 1945 features
```

**Fichier crÃ©Ã© :**
- `MASTER_dataset_all_sensors.txt` (2205 Ã— 1945)

---

## ğŸ·ï¸ 4. Extraction des Labels

### Source
- **Fichier** : profile.txt (contient plusieurs colonnes)
- **Colonne utilisÃ©e** : feature_1 = valve_condition

### Extraction
```python
valve_condition = profile_df['feature_1']
```

**Classes :**
- **100** : Valve en condition optimale
- **90** : LÃ©gÃ¨re dÃ©gradation
- **80** : DÃ©gradation moyenne
- **73** : Valve dÃ©faillante

**Fichier crÃ©Ã© :**
- `valve_condition.txt` (2205 Ã— 1)

---

## ğŸ‰ 5. Dataset Final Complet

### ConcatÃ©nation Finale
```python
final_dataset = [master_dataset | valve_condition]
                     1945          +       1       = 1946 colonnes
```

### Structure du Dataset Final

| Colonnes | Contenu | Description |
|----------|---------|-------------|
| 0 - 1199 | PS features | 5 capteurs de pression (fenÃªtrÃ©s) |
| 1200 - 1679 | FS features | 2 capteurs de dÃ©bit (fenÃªtrÃ©s) |
| 1680 - 1919 | EPS features | 1 capteur pression externe (fenÃªtrÃ©) |
| 1920 - 1939 | TS features | 4 capteurs tempÃ©rature (agrÃ©gÃ©s) |
| 1940 - 1944 | VS features | 1 capteur vibration (agrÃ©gÃ©) |
| **1945** | **Label** | **valve_condition (100, 90, 80, 73)** |

### CaractÃ©ristiques Finales
- **Shape** : 2205 cycles Ã— 1946 colonnes
- **Features** : 1945 (tous les capteurs combinÃ©s)
- **Label** : 1 (condition de la valve)
- **Format** : PrÃªt pour l'apprentissage supervisÃ©

**Fichier crÃ©Ã© :**
- `FINAL_dataset_with_labels.txt` (2205 Ã— 1946)

---

## ğŸ“ˆ 6. RÃ©sumÃ© des RÃ©ductions

| Capteur(s) | Original | Final | RÃ©duction |
|------------|----------|-------|-----------|
| PS (5) | 30,000 pts | 1200 features | **25x** |
| EPS (1) | 6,000 pts | 240 features | **25x** |
| FS (2) | 1,200 pts | 480 features | **2.5x** |
| TS (4) | 240 pts | 20 features | **12x** |
| VS (1) | 60 pts | 5 features | **12x** |
| **TOTAL** | **37,500 pts** | **1945 features** | **~19x** |

---

## ğŸš€ 7. Prochaines Ã‰tapes ML

### Pipeline d'EntraÃ®nement

1. **SÃ©parer X et y**
   ```python
   X = final_dataset.iloc[:, :-1]  # Features (1945 colonnes)
   y = final_dataset.iloc[:, -1]   # Labels (valve_condition)
   ```

2. **Normalisation**
   ```python
   from sklearn.preprocessing import StandardScaler
   scaler = StandardScaler()
   X_scaled = scaler.fit_transform(X)
   ```

3. **Split Train/Test**
   ```python
   from sklearn.model_selection import train_test_split
   X_train, X_test, y_train, y_test = train_test_split(
       X_scaled, y, test_size=0.2, random_state=42, stratify=y
   )
   ```

4. **EntraÃ®nement du ModÃ¨le**
   ```python
   from sklearn.ensemble import RandomForestClassifier
   model = RandomForestClassifier(n_estimators=100, random_state=42)
   model.fit(X_train, y_train)
   ```

5. **Ã‰valuation**
   ```python
   from sklearn.metrics import classification_report, confusion_matrix
   y_pred = model.predict(X_test)
   print(classification_report(y_test, y_pred))
   ```

---

## âœ… Ce que tu as accompli

âœ¨ **Pipeline complet de feature engineering multi-frÃ©quences**
âœ¨ **13 capteurs** â†’ **1945 features cohÃ©rentes**
âœ¨ **FenÃªtrage intelligent** pour capteurs haute frÃ©quence
âœ¨ **AgrÃ©gation globale** pour capteurs basse frÃ©quence
âœ¨ **Dataset final unifiÃ©** avec features + labels alignÃ©s
âœ¨ **RÃ©duction massive** (~19x) tout en prÃ©servant l'information essentielle
âœ¨ **PrÃªt pour l'entraÃ®nement** de modÃ¨les ML de classification

ğŸ¯ **Tu as transformÃ© 37,500 points bruts en 1,945 features intelligentes !**


Ã‰tape 0 â€” Verrouiller ton dataset final

Objectif : Ãªtre sÃ»r que ton X (features) et ton y (valve condition) sont clean.

Ã€ vÃ©rifier avant tout :

1 ligne = 1 cycle (index ou colonne cycle)

y = colonne 2 de profile (100/90/80/73)

pas de valeurs manquantes

pas de colonnes constantes (ex : PS4 dÃ©jÃ  retirÃ©)

toutes les colonnes sont numÃ©riques

Livrable :

un tableau final â€œprÃªt MLâ€ (features + label) + un mini rÃ©sumÃ© (nb cycles, nb features, classes de y)

Ã‰tape 1 â€” Visualisations utiles (pour comprendre et pour ton rapport)

Objectif : montrer que tu comprends ce que ton modÃ¨le va apprendre.

A. Distribution des classes (valve condition)

Compter combien de cycles sont 100, 90, 80, 73

Visualiser (bar chart)

Pourquoi : Ã§a te dit si ton dataset est dÃ©sÃ©quilibrÃ© â†’ impact sur les mÃ©triques.

B. Visualiser quelques features â€œimportantesâ€ par classe

Choisis 5â€“10 features comprÃ©hensibles :

ex. PS1_mean_w10, PS2_std_w9, FS1_mean_w12, TS4_slope, EPS1_std_w8

Regarde :

distribution par classe (boxplots / violins)

corrÃ©lation simple (heatmap sur un sous-ensemble)

Pourquoi : tu vÃ©rifies que certaines variables sÃ©parent bien les classes.

C. PCA / t-SNE (optionnel mais trÃ¨s parlant)

Projeter ton dataset en 2D et colorer par classe
Pourquoi : si les classes se sÃ©parent dÃ©jÃ , ton modÃ¨le va bien marcher.

Livrable :

2â€“3 figures propres + 3 phrases dâ€™interprÃ©tation max (courtes et claires)

Ã‰tape 2 â€” Normalisation / Standardisation (prÃ©parer les donnÃ©es)

Objectif : rendre les features comparables et Ã©viter quâ€™une feature domine juste par son Ã©chelle.

Quelle normalisation choisir ?

Si tu utilises un modÃ¨le basÃ© sur distance (SVM, KNN, rÃ©gression logistique) â†’ standardisation indispensable

Si tu utilises Random Forest / XGBoost â†’ pas obligatoire, mais Ã§a reste propre si tu compares des modÃ¨les

TrÃ¨s important : Ã©viter la fuite de donnÃ©es

Tu dois :

calculer la normalisation uniquement sur le train (2000 premiers cycles)

appliquer ensuite la mÃªme transformation au test (cycles restants)

Livrable :

une section â€œPrÃ©traitementâ€ dans ton rapport expliquant que la standardisation est fit sur le train uniquement.

Ã‰tape 3 â€” Split Train/Test comme tu lâ€™as demandÃ©

Objectif : respecter ta contrainte â€œ2000 premiers cycles = train, reste = test finalâ€.

Ton split :

Train : cycles 1 â†’ 2000

Test final : cycles 2001 â†’ fin

Attention importante (Ã  mentionner)

Ce dataset suit souvent une Ã©volution â€œdans le tempsâ€ (dÃ©gradation progressive).
Ton split par ordre des cycles simule une situation rÃ©aliste :

tu entraÃ®nes sur le passÃ©

tu testes sur le futur

ğŸ‘‰ Câ€™est trÃ¨s dÃ©fendable, mais Ã§a peut Ãªtre plus dur quâ€™un split alÃ©atoire.

Livrable :

afficher les tailles train/test

vÃ©rifier que les classes dans le test existent bien (ex : si une classe nâ€™apparaÃ®t pas du tout dans le test, câ€™est un souci)

Ã‰tape 4 â€” Choisir un modÃ¨le et construire une baseline

Objectif : avoir un modÃ¨le simple qui marche, interprÃ©table, facile Ã  dÃ©fendre.

ModÃ¨le recommandÃ© pour ton cas

Random Forest (excellent baseline)

robuste

interprÃ©table (importance des features)

marche trÃ¨s bien sur features agrÃ©gÃ©es

Option si tu veux comparer

Logistic Regression (avec standardisation)

SVM (avec standardisation)

Gradient Boosting (si tu veux pousser un peu)

Livrable :

un modÃ¨le baseline entraÃ®nÃ©

un tableau de rÃ©sultats sur le test final

Ã‰tape 5 â€” Ã‰valuer le modÃ¨le sur le test final

Objectif : rÃ©pondre exactement Ã  â€œÃ‰valuez sur lâ€™Ã©chantillon de test finalâ€.

MÃ©triques Ã  produire

Accuracy (ok mais insuffisant seul)

Matrice de confusion (indispensable)

Precision / Recall / F1 par classe (surtout si dÃ©sÃ©quilibre)

(optionnel) Balanced accuracy

Ce que tu dois commenter

quelles classes sont le plus confondues (ex : 90 vs 80)

est-ce que le modÃ¨le dÃ©tecte bien les cas â€œ73â€ (quasi panne)

est-ce que â€œ100â€ est trÃ¨s bien reconnu

Livrable :

matrice de confusion + classification report + 5 lignes dâ€™analyse

Ã‰tape 6 â€” InterprÃ©tation : quelles features comptent ?

Objectif : faire la partie â€œingÃ©nierieâ€ + gagner des points.

Deux choses super efficaces :

Top 15 importances (Random Forest)

regrouper par capteur (ex : PS vs FS vs TS)

Ce que tu veux montrer :

les transitoires (fenÃªtres autour des commutations) sont discriminants

les capteurs de dÃ©bit et puissance apportent du signal

TS/VS apportent du contexte

Livrable :

un bar chart des top features + explication courte

Ã‰tape 7 â€” Tests unitaires

Objectif : prouver que ton code est fiable et rÃ©-exÃ©cutable.

Tu ne testes pas â€œle MLâ€ directement, tu testes les composants critiques.

Tests utiles (et rÃ©alistes)

Test dâ€™alignement des cycles

vÃ©rifier que X et y ont le mÃªme nombre de lignes

vÃ©rifier que le cycle i correspond bien au label i

Test de features

pas de NaN

pas dâ€™inf

dimensions attendues (nb de colonnes)

Test de prÃ©traitement

standardizer fit sur train seulement

transformer(train) et transformer(test) fonctionnent

Test de prÃ©diction

un cycle donnÃ© renvoie une prÃ©diction parmi {100, 90, 80, 73}

Livrable :

une suite de tests qui passe en local et en Docker

Ã‰tape 8 â€” Containerisation (Docker)

Objectif : permettre Ã  quelquâ€™un de lancer ton projet en 2 commandes.

Ã€ inclure dans lâ€™image

ton code

ton modÃ¨le entraÃ®nÃ© (ou un script qui lâ€™entraÃ®ne)

les dÃ©pendances (requirements)

un point dâ€™entrÃ©e clair

Deux modes possibles

Mode 1 : â€œtrain + evaluateâ€

Mode 2 : â€œrun app streamlitâ€

Livrable :

Dockerfile + README â€œcomment exÃ©cuterâ€

Ã‰tape 9 â€” Application Web Streamlit

Objectif : prÃ©dire lâ€™Ã©tat de la valve Ã  partir dâ€™un numÃ©ro de cycle.

Interface simple

input : numÃ©ro de cycle (ex : 1500)

bouton : â€œPredictâ€

output :

classe prÃ©dite (100/90/80/73)

(bonus) probas par classe

(bonus) 5 features principales de ce cycle

Point clÃ©

Ton app doit :

charger le dataset final (features)

rÃ©cupÃ©rer la ligne correspondant au cycle

appliquer la mÃªme normalisation (si utilisÃ©e)

appeler le modÃ¨le

afficher rÃ©sultat

Livrable :

une app reproductible, claire, qui marche avec Docker

Ã‰tape 10 â€” Structure recommandÃ©e du projet (pour Ãªtre propre)

Tu vas avoir quelque chose comme :

data/ (dataset final ou chemin)

src/ (prÃ©traitement, modÃ¨le, prÃ©diction)

tests/

models/ (modÃ¨le sauvegardÃ©)

app/ (streamlit)

Dockerfile

README.md

Livrable :

structure claire + instructions dâ€™exÃ©cution

Par quoi tu commences maintenant ?

Dans lâ€™ordre le plus efficace :

Visualisations essentielles (classes + quelques features)

Split 2000 / reste

Standardisation (fit train, apply test)

Random Forest baseline

Ã‰valuation + confusion matrix

Sauvegarder modÃ¨le + pipeline

Streamlit

Tests unitaires

Docker + README