# Valve Condition Monitoring ‚Äî Guide d‚Äôex√©cution (Mode 2 Streamlit)

Ce guide explique ce qui a √©t√© mis en place et comment lancer les tests et l‚Äôapplication web (Mode 2 : Streamlit) en local et via Docker.

---

## 1) Ce qui a √©t√© impl√©ment√©

- Pipeline ML dans `src/pipeline.py` :
  - Chargement du dataset final `FINAL_DATASET_READY_FOR_ML.csv`
  - Split s√©quentiel (Train = cycles 1‚Üí2000, Test = 2001‚ÜíN)
  - Chargement des artefacts sauvegard√©s : `models/random_forest_model.pkl` (mod√®le), `models/scaler.pkl` (StandardScaler)
  - Pr√©diction pour un cycle donn√© (classe + probabilit√©s si dispo)
  - Extraction Top 5 features importantes (RandomForest)
- Application Streamlit dans `app/app.py` (Mode 2) :
  - Entr√©e : num√©ro de cycle
  - Affichage : classe pr√©dite, probabilit√©s par classe, top 5 features et leurs valeurs pour ce cycle
- Tests unitaires dans `tests/test_pipeline.py` :
  - Dataset OK : alignement X/y, absence de NaN/Inf, 1945 features
  - Split OK : respect du d√©coupage 1‚Üí2000 / 2001‚ÜíN
  - Standardisation OK : transform sur train/test, dimensions inchang√©es, train ‚âà centr√©
  - Pr√©diction OK : une ligne ‚Üí une classe ‚àà {100, 90, 80, 73} ; somme des probas ‚âà 1
- Packaging : `requirements.txt` mis √† jour (scikit-learn, joblib, streamlit, pytest)
- Conteneur Mode 2 : `Dockerfile` pour lancer `app/app.py` avec les artefacts et le dataset

---

## 2) Pr√©requis

- Windows + PowerShell
- Python 3.11+ recommand√©
- Dataset pr√©sent : `FINAL_DATASET_READY_FOR_ML.csv`
- Artefacts pr√©sents : `models/random_forest_model.pkl`, `models/scaler.pkl`

---

## 3) Installation des d√©pendances (local)

Dans le dossier du projet :

```powershell
pip install -r requirements.txt
```

Si vous utilisez un venv sp√©cifique, activez-le avant (exemples) :

```powershell
# Exemples
# & "C:\Path\to\myvenv\Scripts\Activate.ps1"
# ou
# & ".venv\Scripts\Activate.ps1"
```

---

## 4) Lancer les tests (pytest)

Ex√©cuter les tests unitaires qui valident le pipeline :

```powershell
python -m pytest -q
```

Si vous devez cibler un Python pr√©cis (ex : venv) :

```powershell
& "C:\Users\steph\OneDrive\Bureau\cour M1 ynov\machine learning\projet final\condition+monitoring+of+hydraulic+systems\myvenv\Scripts\python.exe" -m pytest -q
```
### ‚úÖ R√©sultat attendu : 6 tests passent

**Ce qui a √©t√© fix√© :**

Le dataset original a 1947 colonnes : `[cycle | 1945 features | valve_condition]`

Avant le fix :
- En excluant uniquement `valve_condition`, on gardait `cycle` (l'identifiant)
- R√©sultat : X avait 1946 colonnes (cycle + 1945 features) ‚ùå
- Le scaler (entra√Æn√© sur 1945 features) rejetait cette entr√©e

Apr√®s le fix :
- En excluant AUSSI la colonne `cycle` (qui est juste un identifiant, pas une feature)
- R√©sultat : X a exactement 1945 colonnes ‚úÖ
- Le scaler et le mod√®le fonctionnent correctement

**Les 6 tests valident :**

| Test | V√©rifie |
|------|---------|
| `test_dataset_alignment` | X et y m√™me longueur, 1945 features exactement, pas de NaN/Inf |
| `test_features_no_nan_inf` | Absence de valeurs NaN ou Inf dans les features |
| `test_split_sequential` | Split correct : train = cycles 1‚Üí2000, test = 2001‚ÜíN |
| `test_standardization_transform` | Scaler transforme train/test, dimensions pr√©serv√©es |
| `test_prediction_single_cycle` | Pr√©diction d'un cycle ‚Üí classe ‚àà {100, 90, 80, 73}, probas ‚âà 1 |
| `test_model_artifacts_exist` | Fichiers RF et scaler pr√©sents dans `models/` |

**Les warnings (non-critiques) :**

```
UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names
```

C'est un avertissement inoffensif : le scaler a √©t√© entra√Æn√© avec les noms de colonnes pandas, mais on lui passe parfois des numpy arrays sans noms. Le scaler fonctionne quand m√™me correctement.
---

## 5) Lancer l‚Äôapp Streamlit (Mode 2) ‚Äî Local

D√©marrer l‚Äôapplication :

```powershell
streamlit run app/app.py
```

Ouvrir ensuite : http://localhost:8501

Workflow :
- Saisir un num√©ro de cycle (ex : 1500)
- Cliquer ¬´ Predict ¬ª
- Voir la classe pr√©dite, les probabilit√©s, et les top 5 features (avec leurs valeurs pour ce cycle)

---

## 6) Docker ‚Äî Build & Run (Mode 2)

### Option A : Docker seul

Construire l'image :

```powershell
docker build -t valve-monitor:app .
```

Lancer le conteneur :

```powershell
docker run --rm -p 8501:8501 valve-monitor:app
```

Ouvrir : http://localhost:8501

L'image embarque :
- `src/`, `app/`, `models/`
- `FINAL_DATASET_READY_FOR_ML.csv`
- D√©pendances de `requirements.txt`

### Option B : Docker Compose (Recommand√©)

**Configuration :**
Le fichier `docker-compose.yml` est configur√© avec :
- üêã Build automatique depuis le Dockerfile
- üåê Port 8501 expos√© pour acc√©der √† l'app Streamlit
- üìÅ Volumes mont√©s pour le d√©veloppement (modification du code sans rebuild)
- üîÑ Restart automatique en cas d'erreur
- üíö Healthcheck pour v√©rifier la disponibilit√© de l'application

**D√©marrer l'application :**

```powershell
docker-compose up -d
```

L'option `-d` lance le conteneur en arri√®re-plan (mode d√©tach√©).

**Acc√©der √† l'application :**

Ouvrir : http://localhost:8501

**Voir les logs :**

```powershell
docker-compose logs -f
```

Le flag `-f` permet de suivre les logs en temps r√©el (Ctrl+C pour quitter).

**Arr√™ter l'application :**

```powershell
docker-compose down
```

Cette commande arr√™te et supprime le conteneur (les volumes/images restent).

**Red√©marrer apr√®s modification :**

```powershell
docker-compose restart
```

**Rebuild apr√®s modification du Dockerfile ou requirements.txt :**

```powershell
docker-compose up -d --build
```

**Avantages de Docker Compose :**
- Configuration simplifi√©e dans un seul fichier YAML
- Gestion facile du cycle de vie (up/down/restart)
- Volumes mont√©s pour d√©veloppement it√©ratif sans rebuild constant
- Healthcheck int√©gr√© pour monitoring
- Commandes courtes et m√©morables

---

## 7) Structure du projet

- `src/` : pipeline et utilitaires
- `app/` : application Streamlit (Mode 2)
- `models/` : artefacts (RF + scaler)
- `tests/` : tests unitaires
- `requirements.txt` : d√©pendances
- `Dockerfile` : conteneur Mode 2
- `docker-compose.yml` : orchestration Docker simplifi√©e
- `FINAL_DATASET_READY_FOR_ML.csv` : dataset final pr√™t ML

---

## 8) D√©pannage (tips)

- Probl√®me de commande `pytest` non trouv√©e : utilisez `python -m pytest -q`
- `streamlit` non trouv√© : `pip install -r requirements.txt` (v√©rifiez le venv actif)
- Dataset manquant : placez `FINAL_DATASET_READY_FOR_ML.csv` √† la racine du projet
- Artefacts manquants : assurez-vous que `models/random_forest_model.pkl` et `models/scaler.pkl` existent
- Cycle non trouv√© : choisissez un cycle valide 1..N (N = nombre de lignes du dataset)

---

## 9) Test rapide en ligne de commande (optionnel)

Le pipeline peut pr√©dire depuis un script (exemple) :

```powershell
python src/pipeline.py
```

Cela affichera une pr√©diction et des infos pour le cycle 1500 (config par d√©faut dans `__main__`).

---

## 10) Prochaines √©tapes (si besoin)

- Mode 1 (train + evaluate) : ajouter `src/train.py` et `src/evaluate.py`, √©tendre Docker pour lancer ces scripts
- Ajouter d'autres services dans `docker-compose.yml` (base de donn√©es, monitoring, etc.)
- Monitoring en production (logs, m√©triques, alertes)
